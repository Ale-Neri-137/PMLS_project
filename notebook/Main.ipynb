{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7ef72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, types\n",
    "from numba import  int8, float64, int64, uint64, intp, void, boolean, int32\n",
    "\n",
    "import os, math, json, shutil, pathlib, tempfile\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from typing import Literal, Optional\n",
    "from multiprocessing import get_context\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import cast\n",
    "from scipy.special import erfcinv\n",
    "\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "from dataclasses import replace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import cm  # for colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319441cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# if notebook is in PMLS_project/notebooks, add PMLS_project\n",
    "sys.path.insert(0, str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d89b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dreamingnetz import ladder_search_parallel, SysConfig, TrialConfig, pool_orchestrator_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197437ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_diagnostics_report(\n",
    "    I_ts_stack,\n",
    "    betas=None,\n",
    "    acc_stack=None,\n",
    "    *,\n",
    "    q_lo=0.20,                  # disorder-guard quantile for acceptance summaries\n",
    "    burn_in=0,                  # int steps, or float fraction in (0,1)\n",
    "    chains=(0, 1),              # which independent chains to analyze (if present)\n",
    "    plot_disorders=10,           # how many representative disorders to plot as lines\n",
    "    trace_walkers=6,            # how many walkers to show in k_w(t) traces\n",
    "    trace_disorder=\"worst\",     # \"worst\" | \"median\" | int disorder index\n",
    "    trace_chain=0,\n",
    "    save_prefix=None,           # e.g. \"diag_\" -> saves diag_*.png\n",
    "    show=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Drop-in PT diagnostics from I_ts (slot->walker time series) and optional acc_stack.\n",
    "\n",
    "    Expected shapes:\n",
    "      - I_ts_stack: (R, B, T, K) or (B, T, K) or (T, K)\n",
    "      - acc_stack : (R, K-1) or (K-1,) (optional)\n",
    "\n",
    "    Returns a dict of computed metrics (arrays are numpy).\n",
    "    Produces plots (matplotlib) unless show=False.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # ---------- normalize input shapes ----------\n",
    "    I = np.asarray(I_ts_stack)\n",
    "    if I.ndim == 4:\n",
    "        R, B, T, K = I.shape\n",
    "    elif I.ndim == 3:\n",
    "        R = 1\n",
    "        B, T, K = I.shape\n",
    "        I = I[None, ...]\n",
    "    elif I.ndim == 2:\n",
    "        R = 1\n",
    "        B = 1\n",
    "        T, K = I.shape\n",
    "        I = I[None, None, ...]\n",
    "    else:\n",
    "        raise ValueError(\"I_ts_stack must have shape (R,B,T,K), (B,T,K), or (T,K).\")\n",
    "\n",
    "    if betas is None:\n",
    "        beta = None\n",
    "    else:\n",
    "        beta = np.asarray(betas, float)\n",
    "        if beta.shape[0] != K:\n",
    "            raise ValueError(f\"betas length {beta.shape[0]} does not match K={K}.\")\n",
    "\n",
    "    # burn-in\n",
    "    if isinstance(burn_in, float):\n",
    "        if not (0.0 <= burn_in < 1.0):\n",
    "            raise ValueError(\"burn_in as float must be in [0,1).\")\n",
    "        t0 = int(np.floor(burn_in * T))\n",
    "    else:\n",
    "        t0 = int(burn_in)\n",
    "    t0 = max(0, min(t0, T - 1))\n",
    "    Teff = T - t0\n",
    "\n",
    "    temperatures = np.sort(1/np.asarray(betas))\n",
    "\n",
    "\n",
    "    # chains to analyze\n",
    "    chains = tuple(int(c) for c in chains)\n",
    "    for c in chains:\n",
    "        if not (0 <= c < B):\n",
    "            raise ValueError(f\"chain index {c} out of range for B={B}.\")\n",
    "\n",
    "    hot_k, cold_k = 0, K - 1\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _roundtrips_from_ends(w_hot, w_cold, K):\n",
    "        \"\"\"\n",
    "        Hot-based round trips: hot->cold->hot for each walker.\n",
    "        Returns (rt_times list, n_rt, rt_rate).\n",
    "        \"\"\"\n",
    "        t_hot_start = np.full(K, -1, dtype=np.int64)\n",
    "        seen_cold   = np.zeros(K, dtype=np.bool_)\n",
    "        rts = []\n",
    "\n",
    "        for t in range(w_hot.shape[0]):\n",
    "            wh = int(w_hot[t])\n",
    "            wc = int(w_cold[t])\n",
    "\n",
    "            # cold visit marks success-in-between if a hot-start exists\n",
    "            if t_hot_start[wc] != -1:\n",
    "                seen_cold[wc] = True\n",
    "\n",
    "            # hot visit closes a round trip if cold was seen\n",
    "            if t_hot_start[wh] != -1 and seen_cold[wh]:\n",
    "                rts.append(t - t_hot_start[wh])\n",
    "\n",
    "            # (re)start from hot\n",
    "            t_hot_start[wh] = t\n",
    "            seen_cold[wh] = False\n",
    "\n",
    "        n_rt = len(rts)\n",
    "        rt_rate = n_rt / max(1, w_hot.shape[0])\n",
    "        return rts, n_rt, rt_rate\n",
    "\n",
    "    def _passages_from_ends(w_hot, w_cold, K):\n",
    "        \"\"\"\n",
    "        One-way end-to-end passage times:\n",
    "          - hot->cold and cold->hot, using \"last end visited\" timestamps per walker.\n",
    "        Returns two lists: tau_hc, tau_ch.\n",
    "        \"\"\"\n",
    "        last_end = np.zeros(K, dtype=np.int8)     # 0 none, +1 hot, -1 cold\n",
    "        last_t   = np.full(K, -1, dtype=np.int64)\n",
    "\n",
    "        tau_hc = []\n",
    "        tau_ch = []\n",
    "\n",
    "        for t in range(w_hot.shape[0]):\n",
    "            wh = int(w_hot[t])\n",
    "            wc = int(w_cold[t])\n",
    "\n",
    "            # cold hit\n",
    "            if last_end[wc] == +1:\n",
    "                tau_hc.append(t - last_t[wc])\n",
    "            last_end[wc] = -1\n",
    "            last_t[wc] = t\n",
    "\n",
    "            # hot hit\n",
    "            if last_end[wh] == -1:\n",
    "                tau_ch.append(t - last_t[wh])\n",
    "            last_end[wh] = +1\n",
    "            last_t[wh] = t\n",
    "\n",
    "        return tau_hc, tau_ch\n",
    "\n",
    "    def _flow_profile_f(I_bt):\n",
    "        \"\"\"\n",
    "        Directional flow profile f(k) from one chain:\n",
    "        I_bt: (Teff, K) slot->walker.\n",
    "        Implements:\n",
    "          label walker by last end visited: +1 (hot), -1 (cold), 0 unknown.\n",
    "          f(k) = P(label=+1 | at slot k), estimated over time, excluding unknown labels.\n",
    "        Returns:\n",
    "          f: (K,) with NaNs possible if denom=0 at a slot (unlikely)\n",
    "          denom: (K,) number of labeled samples accumulated at each slot\n",
    "        \"\"\"\n",
    "        labels = np.zeros(K, dtype=np.int8)  # per walker: 0 unknown, +1 hot, -1 cold\n",
    "        num = np.zeros(K, dtype=np.float64)\n",
    "        den = np.zeros(K, dtype=np.float64)\n",
    "\n",
    "        for t in range(I_bt.shape[0]):\n",
    "            wh = int(I_bt[t, hot_k])\n",
    "            wc = int(I_bt[t, cold_k])\n",
    "            labels[wh] = +1\n",
    "            labels[wc] = -1\n",
    "\n",
    "            lab_slots = labels[I_bt[t]]  # (K,)\n",
    "            known = (lab_slots != 0)\n",
    "            den[known] += 1.0\n",
    "            num[known] += (lab_slots[known] == +1)\n",
    "\n",
    "        f = np.full(K, np.nan, dtype=np.float64)\n",
    "        mask = den > 0\n",
    "        f[mask] = num[mask] / den[mask]\n",
    "        return f, den\n",
    "\n",
    "    def _invert_perm(I_t):\n",
    "        \"\"\"Given I_t (K,) slot->walker, return k_of_w (K,) walker->slot.\"\"\"\n",
    "        k_of_w = np.empty(K, dtype=np.int16)\n",
    "        k_of_w[I_t.astype(np.int64)] = np.arange(K, dtype=np.int16)\n",
    "        return k_of_w\n",
    "\n",
    "    def _backtracking_rho1(I_bt, walkers=None):\n",
    "        \"\"\"\n",
    "        Backtracking correlation rho1 = Corr(delta k(t), delta k(t+1)) for selected walkers,\n",
    "        where k_w(t) is walker position (slot index).\n",
    "        Returns:\n",
    "          rho_w: (len(walkers),) rho1 per walker (NaN if too few moves)\n",
    "          rho_med: median rho1 ignoring NaNs\n",
    "        \"\"\"\n",
    "        Te = I_bt.shape[0]\n",
    "        if walkers is None:\n",
    "            walkers = np.arange(K, dtype=np.int64)\n",
    "        else:\n",
    "            walkers = np.asarray(walkers, dtype=np.int64)\n",
    "\n",
    "        # build k_w(t) for selected walkers only, streaming\n",
    "        k_prev = _invert_perm(I_bt[0])[walkers].astype(np.int16)\n",
    "        dk_prev = None\n",
    "        xs = [[] for _ in range(walkers.size)]\n",
    "        ys = [[] for _ in range(walkers.size)]\n",
    "\n",
    "        for t in range(1, Te):\n",
    "            k_now = _invert_perm(I_bt[t])[walkers].astype(np.int16)\n",
    "            dk = (k_now - k_prev).astype(np.int16)\n",
    "            if dk_prev is not None:\n",
    "                for i in range(walkers.size):\n",
    "                    xs[i].append(int(dk_prev[i]))\n",
    "                    ys[i].append(int(dk[i]))\n",
    "            dk_prev = dk\n",
    "            k_prev = k_now\n",
    "\n",
    "        rho = np.full(walkers.size, np.nan, dtype=np.float64)\n",
    "        for i in range(walkers.size):\n",
    "            x = np.array(xs[i], dtype=np.float64)\n",
    "            y = np.array(ys[i], dtype=np.float64)\n",
    "            if x.size >= 10 and np.std(x) > 0 and np.std(y) > 0:\n",
    "                rho[i] = np.corrcoef(x, y)[0, 1]\n",
    "        rho_med = np.nanmedian(rho)\n",
    "        return rho, rho_med\n",
    "\n",
    "    # ---------- compute per-disorder, per-chain metrics ----------\n",
    "    rt_count = np.zeros((R, B), dtype=np.int64)\n",
    "    rt_rate  = np.zeros((R, B), dtype=np.float64)\n",
    "    rt_med   = np.full((R, B), np.nan, dtype=np.float64)\n",
    "\n",
    "    tau_hc_med = np.full((R, B), np.nan, dtype=np.float64)\n",
    "    tau_ch_med = np.full((R, B), np.nan, dtype=np.float64)\n",
    "\n",
    "    f_prof = np.full((R, B, K), np.nan, dtype=np.float64)\n",
    "    f_slope_max = np.full((R, B), np.nan, dtype=np.float64)\n",
    "\n",
    "    rho1_med = np.full((R, B), np.nan, dtype=np.float64)\n",
    "\n",
    "    for r in range(R):\n",
    "        for b in chains:\n",
    "            I_bt = I[r, b, t0:, :].astype(np.int64)  # (Teff,K)\n",
    "            w_hot  = I_bt[:, hot_k]\n",
    "            w_cold = I_bt[:, cold_k]\n",
    "\n",
    "            rts, nrt, rate = _roundtrips_from_ends(w_hot, w_cold, K)\n",
    "            rt_count[r, b] = nrt\n",
    "            rt_rate[r, b]  = rate\n",
    "            if rts:\n",
    "                rt_med[r, b] = float(np.median(np.array(rts, dtype=np.int64)))\n",
    "\n",
    "            tau_hc, tau_ch = _passages_from_ends(w_hot, w_cold, K)\n",
    "            if tau_hc:\n",
    "                tau_hc_med[r, b] = float(np.median(np.array(tau_hc, dtype=np.int64)))\n",
    "            if tau_ch:\n",
    "                tau_ch_med[r, b] = float(np.median(np.array(tau_ch, dtype=np.int64)))\n",
    "\n",
    "            f, _den = _flow_profile_f(I_bt)\n",
    "            f_prof[r, b, :] = f\n",
    "            if np.all(np.isnan(f)):\n",
    "                f_slope_max[r, b] = np.nan\n",
    "            else:\n",
    "                df = np.diff(f)\n",
    "                f_slope_max[r, b] = np.nanmax(np.abs(df))\n",
    "\n",
    "            # backtracking correlation on a small subset of walkers (cheap + informative)\n",
    "            walkers = np.linspace(0, K - 1, min(trace_walkers, K), dtype=np.int64)\n",
    "            _rho, rho_med_val = _backtracking_rho1(I_bt, walkers=walkers)\n",
    "            rho1_med[r, b] = rho_med_val\n",
    "\n",
    "    # ---------- acceptance aggregation (optional) ----------\n",
    "    acc_summary = None\n",
    "    if acc_stack is not None:\n",
    "        A = np.asarray(acc_stack, float)\n",
    "        if A.ndim == 1:\n",
    "            if A.shape[0] != K - 1:\n",
    "                raise ValueError(\"acc_stack length must be K-1.\")\n",
    "            acc_med = A.copy()\n",
    "            acc_lo  = A.copy()\n",
    "            acc_hi  = A.copy()\n",
    "        elif A.ndim == 2:\n",
    "            if A.shape[1] != K - 1:\n",
    "                raise ValueError(\"acc_stack must have shape (R,K-1).\")\n",
    "            acc_med = np.quantile(A, 0.50, axis=0)\n",
    "            acc_lo  = np.quantile(A, q_lo, axis=0)\n",
    "            acc_hi  = np.quantile(A, 1.0 - q_lo, axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"acc_stack must be shape (K-1,) or (R,K-1).\")\n",
    "\n",
    "        acc_summary = dict(acc_med=acc_med, acc_lo=acc_lo, acc_hi=acc_hi)\n",
    "\n",
    "    # ---------- choose representative disorders ----------\n",
    "    # Use median over analyzed chains of rt_rate to rank disorders\n",
    "    rt_rate_used = np.nanmedian(rt_rate[:, list(chains)], axis=1)\n",
    "    worst_r = int(np.nanargmin(rt_rate_used))\n",
    "    best_r  = int(np.nanargmax(rt_rate_used))\n",
    "    med_r   = int(np.argsort(rt_rate_used)[len(rt_rate_used)//2]) if R > 1 else 0\n",
    "\n",
    "    if trace_disorder == \"worst\":\n",
    "        trace_r = worst_r\n",
    "    elif trace_disorder == \"median\":\n",
    "        trace_r = med_r\n",
    "    elif isinstance(trace_disorder, int):\n",
    "        trace_r = int(trace_disorder)\n",
    "    else:\n",
    "        raise ValueError(\"trace_disorder must be 'worst', 'median', or an int index.\")\n",
    "\n",
    "    reps = [worst_r, med_r, best_r]\n",
    "    reps = reps[:min(plot_disorders, len(reps))]\n",
    "\n",
    "    # ---------- plots ----------\n",
    "    figs = []\n",
    "\n",
    "    # 1) Acceptance per interface (median/low/high quantiles across disorders)\n",
    "    if acc_summary is not None:\n",
    "        fig = plt.figure(figsize=(7, 3.8))\n",
    "        x = np.arange(K - 1)\n",
    "        plt.axhline(0.2, linestyle=\"--\")\n",
    "        plt.plot(x,A.min(axis=0), marker=\"o\", linestyle=\":\", label=\"acc min\")\n",
    "        plt.plot(x, acc_summary[\"acc_med\"], marker=\"o\", linestyle=\"-\", label=\"acc median\")\n",
    "        plt.plot(x, acc_summary[\"acc_lo\"],  marker=\"o\", linestyle=\"--\", label=f\"acc q={q_lo:.2f}\")\n",
    "        plt.plot(x, acc_summary[\"acc_hi\"],  marker=\"o\", linestyle=\"--\", label=f\"acc q={1-q_lo:.2f}\")\n",
    "        plt.xlabel(\"interface k (between β_k and β_{k+1})\")\n",
    "        plt.ylabel(\"acceptance\")\n",
    "        plt.title(\"Swap acceptance summaries across disorder\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        figs.append((\"acceptance\", fig))\n",
    "\n",
    "    # 2) Round-trip rate per disorder (scatter)\n",
    "    fig = plt.figure(figsize=(7, 3.8))\n",
    "\n",
    "    rate1 = 100 / max(1, Teff)\n",
    "    rate2 = 2/ max(1, Teff)\n",
    "    plt.axhline(rate1, linestyle=\"--\",label=f\"{100} round trips\")\n",
    "    plt.axhline(rate2, linestyle=\"--\",label=f\"{2} round trips\")\n",
    "    x = np.arange(R)\n",
    "    for b in chains:\n",
    "        plt.plot(x, rt_rate[:, b], marker=\"o\", linestyle=\"none\", label=f\"chain {b}\")\n",
    "    plt.xlabel(\"disorder index r\")\n",
    "    plt.ylabel(\"round trips per step\")\n",
    "    plt.title(f\"Round-trip rate (burn-in t0={t0}, Teff={Teff})\")\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    figs.append((\"rt_rate\", fig))\n",
    "\n",
    "    # 3) Round-trip time median per disorder\n",
    "    fig = plt.figure(figsize=(7, 3.8))\n",
    "    for b in chains:\n",
    "        plt.plot(x, rt_med[:, b], marker=\"o\", linestyle=\"none\", label=f\"chain {b}\")\n",
    "    plt.xlabel(\"disorder index r\")\n",
    "    plt.ylabel(\"median RT time (steps)\")\n",
    "    plt.title(\"Median hot→cold→hot round-trip time\")\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    figs.append((\"rt_median_time\", fig))\n",
    "\n",
    "    order = np.argsort(rt_rate_used)          # worst -> best\n",
    "    mid = len(order) // 2\n",
    "\n",
    "    groups = {\n",
    "        \"worst 3\": order[:3],\n",
    "        \"median ±1\": order[max(0, mid-1):min(len(order), mid+2)],\n",
    "        \"best 3\": order[-3:],\n",
    "    }\n",
    "\n",
    "    x = np.arange(K)  # slot index; or use beta / (1/beta) if you want later\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3.8), sharey=True)\n",
    "    for ax, (title, idxs) in zip(axes, groups.items()):\n",
    "        for r in idxs:\n",
    "            for b in chains:\n",
    "                ax.plot(x, f_prof[r, b], marker=\"o\", linestyle=\"-\", label=f\"r={r}, b={b}\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"slot k (0 hot → K-1 cold)\")\n",
    "    axes[0].set_ylabel(\"f(k)\")\n",
    "    axes[0].legend(ncol=1, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    figs.append((\"flow_groups\", fig))\n",
    "\n",
    "\n",
    "    # 5) Heatmap of f(k) across disorders (one chain)\n",
    "    if R > 1:\n",
    "        fig = plt.figure(figsize=(7, 4.2))\n",
    "        M = f_prof[:, trace_chain, :]\n",
    "        plt.imshow(M, aspect=\"auto\", interpolation=\"nearest\")\n",
    "        plt.colorbar(label=\"f(k)\")\n",
    "        plt.xlabel(\"temperature slot k\")\n",
    "        plt.ylabel(\"disorder index r\")\n",
    "        plt.title(f\"f(k) heatmap across disorders (chain {trace_chain})\")\n",
    "        plt.tight_layout()\n",
    "        figs.append((\"flow_heatmap\", fig))\n",
    "\n",
    "    # 6) Walker traces k_w(t) for a few walkers in a chosen disorder\n",
    "    # This is where k_ts matters: for visualization/debug of \"bouncing\"/plateaus.\n",
    "    fig = plt.figure(figsize=(7, 4.2))\n",
    "    I_bt = I[trace_r, trace_chain, t0:, :].astype(np.int64)\n",
    "    Te = I_bt.shape[0]\n",
    "    walkers = np.linspace(0, K - 1, min(trace_walkers, K), dtype=np.int64)\n",
    "\n",
    "    # build k_w(t) for selected walkers\n",
    "    k_tr = np.empty((Te, walkers.size), dtype=np.int16)\n",
    "    for t in range(Te):\n",
    "        k_of_w = _invert_perm(I_bt[t])\n",
    "        k_tr[t, :] = k_of_w[walkers]\n",
    "\n",
    "    t_axis = np.arange(Te)\n",
    "    for i, w in enumerate(walkers):\n",
    "        plt.plot(t_axis, k_tr[:, i], linestyle=\"-\", label=f\"w={int(w)}\")\n",
    "    plt.xlabel(\"time step (post burn-in)\")\n",
    "    plt.ylabel(\"temperature slot k_w(t)\")\n",
    "    plt.title(f\"Walker temperature trajectories (r={trace_r}, chain={trace_chain})\")\n",
    "    plt.legend(ncol=2, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    figs.append((\"walker_traces\", fig))\n",
    "\n",
    "    # 7) Backtracking (rho1) per disorder\n",
    "    fig = plt.figure(figsize=(7, 3.8))\n",
    "    for b in chains:\n",
    "        plt.plot(np.arange(R), rho1_med[:, b], marker=\"o\", linestyle=\"none\", label=f\"chain {b}\")\n",
    "    plt.axhline(0.0, linestyle=\"--\")\n",
    "    plt.xlabel(\"disorder index r\")\n",
    "    plt.ylabel(\"median ρ₁ over sampled walkers\")\n",
    "    plt.title(\"Backtracking indicator: Corr(Δk(t), Δk(t+1))\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    figs.append((\"backtracking\", fig))\n",
    "\n",
    "    # ---------- save / show ----------\n",
    "    if save_prefix is not None:\n",
    "        for name, fig in figs:\n",
    "            fig.savefig(f\"{save_prefix}{name}.png\", dpi=150)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        # avoid GUI side effects; caller can manage figures\n",
    "        pass\n",
    "\n",
    "    # ---------- return metrics ----------\n",
    "    out = dict(\n",
    "        shape=dict(R=R, B=B, T=T, K=K, burn_in=t0, Teff=Teff),\n",
    "        betas=beta,\n",
    "        acc_summary=acc_summary,\n",
    "        rt_count=rt_count,\n",
    "        rt_rate=rt_rate,\n",
    "        rt_med=rt_med,\n",
    "        tau_hc_med=tau_hc_med,\n",
    "        tau_ch_med=tau_ch_med,\n",
    "        f_profile=f_prof,\n",
    "        f_slope_max=f_slope_max,\n",
    "        rho1_med=rho1_med,\n",
    "        representative=dict(worst=worst_r, median=med_r, best=best_r, trace=trace_r),\n",
    "    )\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6052565",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "α = 0.04\n",
    "\n",
    "P = int(α*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9274387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed488e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "pass  1 | K= 8 | \n",
      " \n",
      "acc_trig=[15  0  0  0 10 49 68]\n",
      " \n",
      "acc_low= [11  0  0  0  8 29 38]\n",
      " \n",
      "＋ insert after iface 0\n",
      "＋ insert after iface 1\n",
      "＋ insert after iface 2\n",
      " \n",
      " \n",
      "pass  2 | K=11 | \n",
      " \n",
      "acc_trig=[55 41  8 11  5  3  0 12 62 94]\n",
      " \n",
      "acc_low= [52 33  5 11  4  2  0  9 45 83]\n",
      " \n",
      "↺ reshape (fixed K)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m sys0  \u001b[38;5;241m=\u001b[39m SysConfig(N\u001b[38;5;241m=\u001b[39mN, P\u001b[38;5;241m=\u001b[39mP, K\u001b[38;5;241m=\u001b[39mbetas0\u001b[38;5;241m.\u001b[39msize, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m,c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, β\u001b[38;5;241m=\u001b[39mbetas0,\n\u001b[1;32m      3\u001b[0m                   mu_to_store\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;66;03m#useless parameter\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                   master_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12345\u001b[39m, spin_init_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m trial \u001b[38;5;241m=\u001b[39m TrialConfig(equilibration_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6000\u001b[39m, sweeps_per_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m betas1, acc_stack1, I_ts_stack1 \u001b[38;5;241m=\u001b[39m \u001b[43mladder_search_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbetas0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA_low\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_high\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_star\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.36\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_lo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# fix \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredistribute_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# number of inserts after which a reshape triggers in the next pass, this triggers very rarely\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_max_for_reshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# max number of lows to still trigger a reshape before the inserts can trigger\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_hot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# number of high T interfaces that ignore the high mask\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_insert\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# max number of inserts allowed between reshapes\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_reshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mclip_reshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.35\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# reshape strength and constraints on the stretching of Δβ_k\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_passes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unipd/PMLS_project/dreamingnetz/beta_ladder_search.py:492\u001b[0m, in \u001b[0;36mladder_search_parallel\u001b[0;34m(sys_template, beta_init, trial, R_workers, R_total, A_low, A_high, A_star, eps, q_lo, redistribute_every, low_max_for_reshape, n_hot, max_insert, gamma_reshape, clip_reshape, K_max, max_passes, verbose, start_method)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# ---- parallel pilot run on current ladder ----\u001b[39;00m\n\u001b[1;32m    491\u001b[0m sys_now \u001b[38;5;241m=\u001b[39m replace(sys_template, K\u001b[38;5;241m=\u001b[39mbetas\u001b[38;5;241m.\u001b[39msize, β\u001b[38;5;241m=\u001b[39mbetas)\n\u001b[0;32m--> 492\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpool_orchestrator_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m acc_stack   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([r\u001b[38;5;241m.\u001b[39macc_edge \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (R, K-1)\u001b[39;00m\n\u001b[1;32m    495\u001b[0m I_ts_stack  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([r\u001b[38;5;241m.\u001b[39mI_ts \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)      \u001b[38;5;66;03m# (R, B, T, K)\u001b[39;00m\n",
      "File \u001b[0;32m~/unipd/PMLS_project/dreamingnetz/beta_ladder_search.py:236\u001b[0m, in \u001b[0;36mpool_orchestrator_stats\u001b[0;34m(sys, trial, R_workers, R_total, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mR_workers, mp_context\u001b[38;5;241m=\u001b[39mmpctx) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    235\u001b[0m     futs \u001b[38;5;241m=\u001b[39m [ex\u001b[38;5;241m.\u001b[39msubmit(worker_run_stats, rid, sys, trial) \u001b[38;5;28;01mfor\u001b[39;00m rid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(R_total)]\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m as_completed(futs): out\u001b[38;5;241m.\u001b[39mappend(f\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# sort by rid\u001b[39;00m\n\u001b[1;32m    238\u001b[0m out\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m r: r\u001b[38;5;241m.\u001b[39mrid)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "betas0 = np.geomspace(0.55, 9, 8)\n",
    "sys0  = SysConfig(N=N, P=P, K=betas0.size, t=0.,c=0, β=betas0,\n",
    "                  mu_to_store=np.array([0]), #useless parameter\n",
    "                  master_seed=12345, spin_init_mode=\"random\")\n",
    "\n",
    "trial = TrialConfig(equilibration_time=6000, sweeps_per_sample=10, n_samples=500)\n",
    "\n",
    "betas1, acc_stack1, I_ts_stack1 = ladder_search_parallel(\n",
    "    sys_template=sys0, beta_init=betas0,\n",
    "    trial=trial, R_workers=10, R_total=10,\n",
    "\n",
    "    A_low=0.14, A_high=0.48, A_star=0.36,\n",
    "    q_lo=0.10,                 # fix \n",
    "    redistribute_every=2,      # number of inserts after which a reshape triggers in the next pass, this triggers very rarely\n",
    "    low_max_for_reshape = 4,   # max number of lows to still trigger a reshape before the inserts can trigger\n",
    "    n_hot = 0,                 # number of high T interfaces that ignore the high mask\n",
    "    max_insert = 3,            # max number of inserts allowed between reshapes\n",
    "\n",
    "    gamma_reshape=0.5,clip_reshape=(0.75, 1.35), # reshape strength and constraints on the stretching of Δβ_k\n",
    "\n",
    "    K_max=45, max_passes=10, verbose=True, start_method = \"fork\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15eafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys1  = SysConfig(N=N, P=P, K=betas1.size, t=0.,c=0, β=betas1,\n",
    "                  mu_to_store=np.array([0]), #useless parameter\n",
    "                  master_seed=12345, spin_init_mode=\"random\")\n",
    "\n",
    "trial1 = TrialConfig(equilibration_time=6000, sweeps_per_sample=50, n_samples=1200)\n",
    "\n",
    "\n",
    "results = pool_orchestrator_stats(sys1, trial1, R_workers=10, R_total=10, start_method=\"fork\")\n",
    "\n",
    "acc_stack1   = np.stack([r.acc_edge for r in results], axis=0)  # (R, K-1)\n",
    "I_ts_stack1  = np.stack([r.I_ts for r in results], axis=0)      # (R, B, T, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041420cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pt_diagnostics_report(\n",
    "    I_ts_stack1,\n",
    "    betas1,\n",
    "    acc_stack1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
